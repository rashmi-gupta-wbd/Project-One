name: Deploy workflow
run-name: Deploy ${{ inputs.deploy_job }} from ${{ inputs.project }}

on:
  #since we do not want it to be triggered on push 
  # Trigger on deployment
  # push:
  #   branches:
  #     - main  # Make sure your push is going to `main`

  #after writing the below code and runnning it, we then commeneted it
  #before commenting we were getting the workflow being run for all the pushes to all the branches
  #next we commented out, so for all the branches that are newly created afterthis, we are getting the workflow for all of them
  #push:
   # branches:
     # - '*'  

 #we want the options to be given to the user, while he wants to run the workflow
  workflow_dispatch:
    inputs:
      environment:
        description: Environment
        default: env1
        required: true
        type: choice
        options:
          - env1
          - env2
          - env3
          - env4
          - env5
          - env6
          - env7
          - env8
          - env9
          - env10
      project:
        description: The project directory containing the job
        required: true
      deploy_job:
        description: Job name
        required: true

jobs:
  deploy:
    runs-on: macos-latest

    steps:
      # Checkout the code from the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Print deployment message
      - name: Print deployment message
        run: |
          echo "Deploying job: ${{ inputs.deploy_job }} from project: ${{ inputs.project }}"

      # Set outputs for the deploy_job and project
      - name: Set Outputs
        id: set_outputs
        run: |
          echo "::set-output name=deploy_job::${{ inputs.deploy_job }}"
          echo "::set-output name=project::${{ inputs.project }}"

      # Trigger Databricks Notebook execution
      - name: Trigger Databricks Notebook
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_INSTANCE: ${{ secrets.DATABRICKS_INSTANCE }}
        run: |
          # Set variables
          NOTEBOOK_PATH="/Workspace/Path/To/Your/Notebook"  # Adjust the path to your notebook
          CLUSTER_ID="your-cluster-id"  # Replace with your Databricks cluster ID
          
          # Create the JSON payload with required parameters
          PAYLOAD=$(cat <<EOF
          {
            "run_name": "Deploy Job - ${{ inputs.deploy_job }}",
            "existing_cluster_id": "$CLUSTER_ID",
            "notebook_task": {
              "notebook_path": "$NOTEBOOK_PATH",
              "base_parameters": {
                "deploy_job": "${{ inputs.deploy_job }}",
                "project": "${{ inputs.project }}"
              }
            }
          }
          EOF
          )

          # Trigger the Databricks notebook using the REST API
          curl -X POST \
            https://$DATABRICKS_INSTANCE/api/2.1/jobs/runs/submit \
            -H "Authorization: Bearer $DATABRICKS_TOKEN" \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD"

